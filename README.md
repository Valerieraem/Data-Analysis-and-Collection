# Data-Analysis-and-Collection
cleaning and collection using a web scraper. Data analysis practice. Using beautiful soup python package and selenium web driver. 
Scraping house details from Trulia. Looking at San Diego, and other cities.
### Start at the notebook file titled: Web Scraping Data Collection Project
Other cities after San Diego are split into their own notebook files to keep it organized. The scraped data from all cities are saved as excel and csv files. 

Running into some issues with captchas, tried to get around them and it did work but not good enough. Cycling IP addresses, using a fake user agent, etc. Will cut the project short and use the data that I currently have instead of scraping more cities so I don't get blocked. Next step is cleaning the data. 

Working on cleaning the data for database use. I completed the cleaning and uploaded the merged data files, one before cleaning and one after cleaning to compare the output. 
